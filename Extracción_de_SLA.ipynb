{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18cqNtQj-Gel"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrc7LvrsnIbL"
      },
      "outputs": [],
      "source": [
        "#Librería para manipular datos\n",
        "import pandas as pd\n",
        "# llamar a la API de Zendesk\n",
        "import numpy as np\n",
        "import httplib2\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "import base64\n",
        "import glob\n",
        "import os\n",
        "from os import walk\n",
        "\n",
        "#config\n",
        "pd.set_option('display.max_columns', None)\n",
        "#@markdown #***INGRESO DE USUARIO***\n",
        "Dominio = '' #@param {type: \"string\"}\n",
        "Email = '' #@param {type:\"string\"}\n",
        "Token = ''#@param {type:\"string\"}\n",
        "start_time=\"\" #@param {type:\"string\"}\n",
        "\n",
        "z_domain= Dominio\n",
        "email= Email\n",
        "contraseña= Token\n",
        "\n",
        "\n",
        "#@markdown\n",
        "authentication=email+\"/token:\"+contraseña\n",
        "message_bytes = authentication.encode('ascii')\n",
        "base64_bytes=base64.b64encode(message_bytes).decode('ascii')\n",
        "\n",
        "headers = {'Authorization': 'Basic '+base64_bytes, 'Content-Type': 'application/json'}\n",
        "\n",
        "carpeta_contenedora=\"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_U-TqhSPQuf"
      },
      "outputs": [],
      "source": [
        "def data_ticket(z_domain,start_time,headers):\n",
        "  url = z_domain+\"/api/v2/incremental/tickets.json?start_time=\"   +start_time+   \"&include=metric_sets,slas\"\n",
        "  status = 0\n",
        "  while status != 200:\n",
        "    r = requests.get(url, headers=headers)\n",
        "    \n",
        "    status = r.status_code\n",
        "    if status == 200:\n",
        "      print(\"----llamada de api exitosa: \", status)\n",
        "      data=json.loads(r.text)\n",
        "      is_cont=data['end_of_stream']\n",
        "      end_time=data['end_time']\n",
        "    else:\n",
        "      print(\"----llamada de api fracasada: \", status)\n",
        "      time.sleep(10)\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  #print(\"cantidad\",data['count'])\n",
        "\n",
        "  df_ticket=pd.DataFrame(data['tickets'])\n",
        "\n",
        "  #se traspasa las variables del metric_set\n",
        "  group_stations=[]\n",
        "  assignee_stations=[]\n",
        "  reopens=[]\n",
        "  replies=[]\n",
        "  assignee_updated_at=[]\n",
        "  requester_updated_at=[]\n",
        "  status_updated_at=[]\n",
        "  initially_assigned_at=[]\n",
        "  assigned_at=[]\n",
        "  solved_at=[]\n",
        "  latest_comment_added_at=[]\n",
        "  reply_time_in_minutes_calendar=[]\n",
        "  reply_time_in_minutes_business=[]\n",
        "  first_resolution_time_in_minutes_calendar=[]\n",
        "  first_resolution_time_in_minutes_business=[]\n",
        "  full_resolution_time_in_minutes_calendar=[]\n",
        "  full_resolution_time_in_minutes_business=[]\n",
        "  agent_wait_time_in_minutes_calendar=[]\n",
        "  agent_wait_time_in_minutes_business=[]\n",
        "  requester_wait_time_in_minutes_calendar=[]\n",
        "  requester_wait_time_in_minutes_business=[]\n",
        "  on_hold_time_in_minutes_calendar=[]\n",
        "  on_hold_time_in_minutes_business=[]\n",
        "\n",
        "  for index, i in enumerate(df_ticket['metric_set']):\n",
        "    try:\n",
        "      group_stations.append(i['group_stations'])\n",
        "      assignee_stations.append(i['assignee_stations'])\n",
        "      reopens.append(i['reopens'])\n",
        "      replies.append(i['replies'])\n",
        "      assignee_updated_at.append(i['assignee_updated_at'])\n",
        "      requester_updated_at.append(i['requester_updated_at'])\n",
        "      status_updated_at.append(i['status_updated_at'])\n",
        "      initially_assigned_at.append(i['initially_assigned_at'])\n",
        "      assigned_at.append(i['assigned_at'])\n",
        "      solved_at.append(i['solved_at'])\n",
        "      latest_comment_added_at.append(i['latest_comment_added_at'])\n",
        "      reply_time_in_minutes_calendar.append(i['reply_time_in_minutes']['calendar'])\n",
        "      reply_time_in_minutes_business.append(i['reply_time_in_minutes']['business'])\n",
        "      first_resolution_time_in_minutes_calendar.append(i['first_resolution_time_in_minutes']['calendar'])\n",
        "      first_resolution_time_in_minutes_business.append(i['first_resolution_time_in_minutes']['business'])\n",
        "      full_resolution_time_in_minutes_calendar.append(i['full_resolution_time_in_minutes']['calendar'])\n",
        "      full_resolution_time_in_minutes_business.append(i['full_resolution_time_in_minutes']['business'])\n",
        "      agent_wait_time_in_minutes_calendar.append(i['agent_wait_time_in_minutes']['calendar'])\n",
        "      agent_wait_time_in_minutes_business.append(i['agent_wait_time_in_minutes']['business'])\n",
        "      requester_wait_time_in_minutes_calendar.append(i['requester_wait_time_in_minutes']['calendar'])\n",
        "      requester_wait_time_in_minutes_business.append(i['requester_wait_time_in_minutes']['business'])\n",
        "      on_hold_time_in_minutes_calendar.append(i['on_hold_time_in_minutes']['calendar'])\n",
        "      on_hold_time_in_minutes_business.append(i['on_hold_time_in_minutes']['business'])\n",
        "    except:\n",
        "      group_stations.append(None)\n",
        "      assignee_stations.append(None)\n",
        "      reopens.append(None)\n",
        "      replies.append(None)\n",
        "      assignee_updated_at.append(None)\n",
        "      requester_updated_at.append(None)\n",
        "      status_updated_at.append(None)\n",
        "      initially_assigned_at.append(None)\n",
        "      assigned_at.append(None)\n",
        "      solved_at.append(None)\n",
        "      latest_comment_added_at.append(None)\n",
        "      reply_time_in_minutes_calendar.append(None)\n",
        "      reply_time_in_minutes_business.append(None)\n",
        "      first_resolution_time_in_minutes_calendar.append(None)\n",
        "      first_resolution_time_in_minutes_business.append(None)\n",
        "      full_resolution_time_in_minutes_calendar.append(None)\n",
        "      full_resolution_time_in_minutes_business.append(None)\n",
        "      agent_wait_time_in_minutes_calendar.append(None)\n",
        "      agent_wait_time_in_minutes_business.append(None)\n",
        "      requester_wait_time_in_minutes_calendar.append(None)\n",
        "      requester_wait_time_in_minutes_business.append(None)\n",
        "      on_hold_time_in_minutes_calendar.append(None)\n",
        "      on_hold_time_in_minutes_business.append(None)\n",
        "\n",
        "  df_ticket['grupos asignados']=group_stations\n",
        "  df_ticket['agentes asignados']=assignee_stations\n",
        "  df_ticket['reaperturas']=reopens\n",
        "  df_ticket['cantidad de respuestas']=replies\n",
        "  df_ticket['ultima actualizacion agente']=assignee_updated_at\n",
        "  df_ticket['ultima actualizacion solicitante']=requester_updated_at\n",
        "  df_ticket['ultima actualizacion estado']=status_updated_at\n",
        "  df_ticket['inicialmente asignado']=initially_assigned_at\n",
        "  df_ticket['fecha asignacion']=assigned_at\n",
        "  df_ticket['ultimo comentario agregado']=latest_comment_added_at\n",
        "  df_ticket['tiempo respuesta calendario']=reply_time_in_minutes_calendar\n",
        "  df_ticket['tiempo respuesta negocio']=reply_time_in_minutes_business\n",
        "  df_ticket['primera resolucion calendario']=first_resolution_time_in_minutes_calendar\n",
        "  df_ticket['primera resolucion negocio']=first_resolution_time_in_minutes_business\n",
        "  df_ticket['resolucion completa calendario']=full_resolution_time_in_minutes_calendar\n",
        "  df_ticket['resolucion completa negocio']=full_resolution_time_in_minutes_business\n",
        "  df_ticket['espera agente calendario']=agent_wait_time_in_minutes_calendar\n",
        "  df_ticket['espera agente negocio']=agent_wait_time_in_minutes_business\n",
        "  df_ticket['espera solicitante calendario']=requester_wait_time_in_minutes_calendar\n",
        "  df_ticket['espera solicitante negocio']=requester_wait_time_in_minutes_business\n",
        "  df_ticket['tiempo espera calendario']=on_hold_time_in_minutes_calendar\n",
        "  df_ticket['tiempo espera negocio']=on_hold_time_in_minutes_business\n",
        "  #time.sleep(6)\n",
        "  ## SLA tratamiento\n",
        "  frt_time_status=[]\n",
        "  frt_time_brkn=[]\n",
        "  frt_time_day_brkn=[]\n",
        "  frt_time_day_brkn_min=[]\n",
        "  agnt_time_status=[]\n",
        "  agnt_time_brkn=[]\n",
        "  agnt_time_day_brkn=[]\n",
        "  agnt_time_day_brkn_min=[]\n",
        "  count_ewq=0\n",
        "  for ind in df_ticket.index:\n",
        "    ad1=None\n",
        "    ad2=None\n",
        "    ad3=None\n",
        "    ad4=None\n",
        "    bd1=None\n",
        "    bd2=None\n",
        "    bd3=None\n",
        "    bd4=None\n",
        "    for x in df_ticket['slas'][ind]['policy_metrics']:\n",
        "      if x['metric']==\"first_reply_time\":\n",
        "        if x['breach_at'] is None:\n",
        "          ad1=x['stage']\n",
        "          ad2=True\n",
        "          ad3=x['breach_at']\n",
        "          ad4=None\n",
        "          break\n",
        "        else:\n",
        "          ad1=x['stage']\n",
        "          ad2=False\n",
        "          ad3=x['breach_at']\n",
        "          if 'days' in x:\n",
        "            ad4=x['days']*1440\n",
        "          if 'hours' in x:\n",
        "            ad4=x['hours']*60\n",
        "          if 'minutes' in x:\n",
        "            ad4=x['minutes']\n",
        "          break\n",
        "    for x in df_ticket['slas'][ind]['policy_metrics']:\n",
        "      if x['metric']==\"agent_work_time\":\n",
        "        if x['breach_at'] is None:\n",
        "          bd1=x['stage']\n",
        "          bd2=True\n",
        "          bd3=x['breach_at']\n",
        "          bd4=None\n",
        "          break\n",
        "        else:\n",
        "          bd1=x['stage']\n",
        "          bd2=False\n",
        "          bd3=x['breach_at']\n",
        "          if 'days' in x:\n",
        "            bd4=x['days']*1440\n",
        "          if 'hours' in x:\n",
        "            bd4=x['hours']*60\n",
        "          if 'minutes' in x:\n",
        "            bd4=x['minutes']\n",
        "          break  \n",
        "    frt_time_status.append(ad1)\n",
        "    frt_time_brkn.append(ad2)\n",
        "    frt_time_day_brkn.append(ad3)\n",
        "    frt_time_day_brkn_min.append(ad4)\n",
        "    agnt_time_status.append(bd1)\n",
        "    agnt_time_brkn.append(bd2)\n",
        "    agnt_time_day_brkn.append(bd3)\n",
        "    agnt_time_day_brkn_min.append(bd4)\n",
        "      \n",
        "\n",
        "\n",
        "  \n",
        "  df_ticket['SLA FIRST RESPONSE - Estado']=frt_time_status\n",
        "  df_ticket['SLA FIRST RESPONSE - ¿Roto?']=frt_time_brkn\n",
        "  df_ticket['SLA FIRST RESPONSE - Fecha roto']=frt_time_day_brkn\n",
        "  df_ticket['SLA FIRST RESPONSE - Tiempo roto']=frt_time_day_brkn_min\n",
        "  df_ticket['SLA AGENT RESPONSE - Estado']=agnt_time_status\n",
        "  df_ticket['SLA AGENT RESPONSE - ¿Roto?']=agnt_time_brkn\n",
        "  df_ticket['SLA AGENT RESPONSE - Fecha roto']=agnt_time_day_brkn\n",
        "  df_ticket['SLA AGENT RESPONSE - Tiempo roto']=agnt_time_day_brkn_min\n",
        "\n",
        "  return df_ticket, is_cont, end_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wsJOrGA7Q1O"
      },
      "outputs": [],
      "source": [
        "def data_user(z_domain,start_time,headers):\n",
        "  continua2=True\n",
        "  continua=True\n",
        "  org_time=str(946684800)\n",
        "  user_time=str(946684800)\n",
        "  all_org={}\n",
        "  iter=1\n",
        "  print(\"---Lo lamentamos, esto puede demorar\")\n",
        "  while continua2:\n",
        "    print(\"---extración de info org iter \"+str(iter)+\",COD \"+org_time)\n",
        "    url2 = z_domain+\"/api/v2/incremental/organizations.json?start_time=\"+org_time\n",
        "    http = httplib2.Http()\n",
        "    response, content = http.request(url2, 'GET', headers=headers)\n",
        "    data2=json.loads(content)\n",
        "    time.sleep(6)\n",
        "    #print(data2)\n",
        "    #print(\"_________\")\n",
        "\n",
        "    if(data2['end_of_stream']):\n",
        "      continua2=False \n",
        "    org_time=str(data2['end_time'])\n",
        "  print(\"---Se obtuvo la información de las organizaciones\")\n",
        "  #__________________________________________________________________________________________________\n",
        "  all_user={}\n",
        "  iter=1\n",
        "  while continua:\n",
        "    print(\"---extración de info usuario iter \"+str(iter)+\",COD \"+user_time)\n",
        "    url = z_domain+\"/api/v2/incremental/users.json?start_time=\"+user_time\n",
        "    http = httplib2.Http()\n",
        "    response, content = http.request(url, 'GET', headers=headers)\n",
        "    data=json.loads(content)\n",
        "    time.sleep(6)\n",
        "    #print(data)\n",
        "    #print(\"_________\")\n",
        "    for idx, x in enumerate(data['users']):\n",
        "      if x['organization_id'] is not None:\n",
        "        nom_org=all_org[str(x['organization_id'])][0]\n",
        "        hh_mm=all_org[str(x['organization_id'])][1]\n",
        "        hh_tt=all_org[str(x['organization_id'])][2]\n",
        "      else:\n",
        "        nom_org=\"\"\n",
        "        hh_mm=0\n",
        "        hh_tt=0\n",
        "      all_user[str(x['id'])]=[x['name'],x['email'],str(nom_org),hh_mm,hh_tt]\n",
        "\n",
        "    if(data['end_of_stream']):\n",
        "      continua=False \n",
        "    user_time=str(data['end_time'])\n",
        "    iter=iter+1\n",
        "  print(\"---Se obtuvo la información de los usuarios\")\n",
        "\n",
        "  return all_user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOSjbf0tP08y"
      },
      "outputs": [],
      "source": [
        "def generarDataSetCamposTicket(z_domain,start_time,headers):    \n",
        "    url = z_domain+\"/api/v2/ticket_fields\"\n",
        "    http = httplib2.Http()\n",
        "    response, content = http.request(url, 'GET', headers=headers)\n",
        "    data=json.loads(content)\n",
        "    campos_de_ticket={}\n",
        "    for idx, x in enumerate(data['ticket_fields']):\n",
        "        id =  data['ticket_fields'][idx]['id']\n",
        "        nombreCampo =  data['ticket_fields'][idx]['title']\n",
        "        type =  data['ticket_fields'][idx]['type']\n",
        "\n",
        "\n",
        "        if type == 'tagger' or type == 'multiselect':\n",
        "            custom_field_options = data['ticket_fields'][idx]['custom_field_options']\n",
        "            opciones_campo = []\n",
        "            for idy, y in enumerate(custom_field_options):\n",
        "                opciones_campo.append([custom_field_options[idy]['raw_name'], custom_field_options[idy]['value']])\n",
        "\n",
        "            campos_de_ticket[id]=[nombreCampo, type, opciones_campo]\n",
        "\n",
        "        if type == 'checkbox':\n",
        "            tag = custom_field_options = data['ticket_fields'][idx]['tag']\n",
        "            campos_de_ticket[id]=[nombreCampo, type, tag]\n",
        "\n",
        "        if type != 'checkbox' and type != 'tagger' and type != 'multiselect':\n",
        "            campos_de_ticket[id]=[nombreCampo, type]\n",
        "\n",
        "    \n",
        "    return campos_de_ticket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHcltN5wrkBb"
      },
      "outputs": [],
      "source": [
        "def generarDataSetFormularios(z_domain,start_time,headers):    \n",
        "    url = z_domain+\"/api/v2/ticket_forms\"\n",
        "    http = httplib2.Http()\n",
        "    response, content = http.request(url, 'GET', headers=headers)\n",
        "    data=json.loads(content)\n",
        "    time.sleep(4)\n",
        "    formularios={}\n",
        "    for idx, x in enumerate(data['ticket_forms']):\n",
        "        id = data['ticket_forms'][idx]['id'];\n",
        "        nombre = data['ticket_forms'][idx]['name'];\n",
        "        formularios[id] = nombre\n",
        "        \n",
        "    return formularios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49f8Gma2rpnC"
      },
      "outputs": [],
      "source": [
        "def generarDataSetAgentes():    \n",
        "    url = z_domain+\"/api/v2/users?role=agent&role=admin\"\n",
        "    http = httplib2.Http()\n",
        "    response, content = http.request(url, 'GET', headers=headers)\n",
        "    data=json.loads(content)\n",
        "\n",
        "    agentes={}\n",
        "    for idx, x in enumerate(data['users']):\n",
        "        id = data['users'][idx]['id'];\n",
        "        nombre = data['users'][idx]['name'];\n",
        "        agentes[id] = nombre\n",
        "        \n",
        "    return agentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbx5Mwggrtji"
      },
      "outputs": [],
      "source": [
        "def generarDataSetMarcas(z_domain,start_time,headers):    \n",
        "    url = z_domain+\"/api/v2/brands\"\n",
        "    http = httplib2.Http()\n",
        "    response, content = http.request(url, 'GET', headers=headers)\n",
        "    data=json.loads(content)\n",
        "    time.sleep(4)\n",
        "    marcas={}\n",
        "    for idx, x in enumerate(data['brands']):\n",
        "        id = data['brands'][idx]['id'];\n",
        "        nombre = data['brands'][idx]['name'];\n",
        "        marcas[id] = nombre\n",
        "        \n",
        "    return marcas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIDJw5VQcE-Y"
      },
      "outputs": [],
      "source": [
        "def generarDataGrupo(z_domain,start_time,headers):    \n",
        "    url = z_domain+\"/api/v2/groups\"\n",
        "    http = httplib2.Http()\n",
        "    response, content = http.request(url, 'GET', headers=headers)\n",
        "    data=json.loads(content)\n",
        "    time.sleep(4)\n",
        "    grupo={}\n",
        "    for idx, x in enumerate(data['groups']):\n",
        "        id = x['id']\n",
        "        nombre = x['name']\n",
        "        grupo[id] = nombre\n",
        "        \n",
        "    return grupo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOctxr_znIbQ"
      },
      "outputs": [],
      "source": [
        "def etl_ticket(z_domain,start_time,headers,carpeta_contenedora):\n",
        "  cont=True\n",
        "  list_csv=[]\n",
        "  N_1=1\n",
        "  print(\"Estamos extrayendo las referencias para este ETL\")\n",
        "  #print(\"-Descargando data formularios\")\n",
        "  #lista_formulario=generarDataSetFormularios(z_domain,start_time,headers)\n",
        "  #print(\"--Cantidad\",len(lista_formulario))\n",
        "  #print(\"-Descargando data usuarios\")\n",
        "  #lista_usuario=data_user(z_domain,start_time,headers)\n",
        "  #print(\"--Cantidad\",len(lista_usuario))\n",
        "  #print(\"-Descargando data campos personalizados\")\n",
        "  #lista_campos=generarDataSetCamposTicket(z_domain,start_time,headers)\n",
        "  #print(\"--Cantidad de campos\",len(lista_campos))\n",
        "  #print(\"-Descargando lista de marcas\")\n",
        "  #lista_marca=generarDataSetMarcas(z_domain,start_time,headers)\n",
        "  #print(\"--Cantidad\",len(lista_marca))\n",
        "  #print(\"-Descargando lista de grupos\")\n",
        "  #lista_grupo=generarDataGrupo(z_domain,start_time,headers)\n",
        "  #print(\"--Cantidad\",len(lista_grupo))\n",
        "  try:\n",
        "    os.remove(carpeta_contenedora+\"/data.csv\")\n",
        "  except:\n",
        "    print(\"No se encontro un archivo data.csv\")\n",
        "  print(\"Parte extracción de los datos de tickets\")\n",
        "  while cont:\n",
        "    print(\"_______________________________________________________\")\n",
        "    print(\"-Iteración \"+str(N_1)+\":\",start_time, \"Trabajando 😔\")\n",
        "    data,cont_1,new_start=data_ticket(z_domain,start_time,headers)\n",
        "    print(\"--Se consiguío los datos de Zendesk\")\n",
        "    \n",
        "    time.sleep(4)\n",
        "    # Información de los usuarios\n",
        "  \n",
        "   \n",
        "\n",
        "    #Se elimina las columnas innecesarias\n",
        "    print(\"--Estoy eliminando columnas innecesarias 😩\")\n",
        "    #data=data.drop(columns=['via',\"forum_topic_id\",\"custom_fields\",\"fields\",\"index\",\"slas\"])\n",
        "    #Estoy actualizando los nombres de las columnas\n",
        "    print(\"--Cambio el nombre de las columnas 🤤\")\n",
        "    #data.rename(columns = {\"type\":\"tipo\",\"subject\":\"asunto\",\"description\":\"descripcion\",\"priority\":\"prioridad\",\"status\":\"estado\",\"recipient\":\"casilla receptora\",\"requester_id\":\"id solicitante\",\"submitter_id\":\"id remitente\",\"assignee_id\":\"id agente asignado\",\"organization_id\":\"id organizacion solicitante\",\"group_id\":\"id grupo asignado\",\"ticket_form_id\":\"id formulario\"}, inplace = True)\n",
        "    #Crear archivo\n",
        "    data.to_csv(carpeta_contenedora+'/'+start_time+\".csv\")\n",
        "    list_csv.append(start_time+\".csv\")\n",
        "    \n",
        "    if(cont_1):\n",
        "      cont=False\n",
        "    start_time=str(new_start)\n",
        "    N_1=N_1+1\n",
        "    print(\"--Lista la transformación 😉\")\n",
        "\n",
        "  \n",
        "  os.chdir(carpeta_contenedora)\n",
        "  file_extension = '.csv'\n",
        "  all_filenames = [i for i in glob.glob(f\"*{file_extension}\")]\n",
        "  combined_csv_data = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
        "\n",
        "\n",
        "  \n",
        "  combined_csv_data = combined_csv_data.loc[:, ~combined_csv_data.columns.str.startswith('Unnamed')]\n",
        "  combined_csv_data.to_csv(\"data.csv\")\n",
        "  for file in list_csv:\n",
        "   os.remove(carpeta_contenedora+\"/\"+file)\n",
        "  print(\"Ya se creo el archivo data_ticket_zerviz.csv 🤤\")\n",
        "\n",
        "  return combined_csv_data\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOgLqdgM6iSk",
        "outputId": "543b2eb3-9afd-4166-9788-b9bcca287470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estamos extrayendo las referencias para este ETL\n",
            "No se encontro un archivo data.csv\n",
            "Parte extracción de los datos de tickets\n",
            "_______________________________________________________\n",
            "-Iteración 1: 1672531200 Trabajando 😔\n",
            "----llamada de api exitosa:  200\n",
            "--Se consiguío los datos de Zendesk\n",
            "--Estoy eliminando columnas innecesarias 😩\n",
            "--Cambio el nombre de las columnas 🤤\n",
            "--Lista la transformación 😉\n",
            "Ya se creo el archivo data_ticket_zerviz.csv 🤤\n"
          ]
        }
      ],
      "source": [
        "df_etl=etl_ticket(z_domain,start_time,headers,carpeta_contenedora)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi2-AroahTCt"
      },
      "outputs": [],
      "source": [
        "df_etl.to_excel(\"archivo.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xAefjwYPMFv"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
